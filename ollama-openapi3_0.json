{
  "openapi": "3.0.3",
  "info": {
    "title": "Ollama API",
    "description": "API for interacting with Ollama models. Ollama allows you to run open-source large language models locally.\nThis specification is based on the official Ollama API documentation.\n",
    "version": "1.0.0",
    "contact": {
      "url": "https://github.com/ollama/ollama"
    }
  },
  "servers": [
    {
      "url": "https://ai-ollama.mwblxq.easypanel.host",
      "description": "Local Ollama server"
    }
  ],
  "paths": {
    "/api/generate": {
      "post": {
        "summary": "Generate a completion for a prompt with a model",
        "description": "Generate a response for a given prompt with the specified model",
        "operationId": "generate",
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/GenerateRequest"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/GenerateResponse"
                }
              }
            }
          },
          "400": {
            "description": "Bad request",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          },
          "404": {
            "description": "Model not found",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          },
          "500": {
            "description": "Internal server error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          }
        }
      }
    },
    "/api/chat": {
      "post": {
        "summary": "Generate a response from a model given a chat history",
        "description": "Generate a chat completion for the given chat history with the specified model",
        "operationId": "chat",
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/ChatRequest"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ChatResponse"
                }
              }
            }
          },
          "400": {
            "description": "Bad request",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          },
          "404": {
            "description": "Model not found",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          },
          "500": {
            "description": "Internal server error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          }
        }
      }
    },
    "/api/embeddings": {
      "post": {
        "summary": "Generate embeddings for a prompt with a model",
        "description": "Generate embeddings for the given prompt with the specified model",
        "operationId": "embeddings",
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/EmbeddingsRequest"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/EmbeddingsResponse"
                }
              }
            }
          },
          "400": {
            "description": "Bad request",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          },
          "404": {
            "description": "Model not found",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          },
          "500": {
            "description": "Internal server error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          }
        }
      }
    },
    "/api/create": {
      "post": {
        "summary": "Create a model from a Modelfile",
        "description": "Create a model from a Modelfile",
        "operationId": "createModel",
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/CreateRequest"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/CreateResponse"
                }
              }
            }
          },
          "400": {
            "description": "Bad request",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          },
          "500": {
            "description": "Internal server error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          }
        }
      }
    },
    "/api/pull": {
      "post": {
        "summary": "Pull a model from a registry",
        "description": "Download a model from a registry to the local library",
        "operationId": "pullModel",
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/PullRequest"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/PullResponse"
                }
              }
            }
          },
          "400": {
            "description": "Bad request",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          },
          "500": {
            "description": "Internal server error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          }
        }
      }
    },
    "/api/push": {
      "post": {
        "summary": "Push a model to a registry",
        "description": "Upload a model from the library to a registry",
        "operationId": "pushModel",
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/PushRequest"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/PushResponse"
                }
              }
            }
          },
          "400": {
            "description": "Bad request",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          },
          "404": {
            "description": "Model not found",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          },
          "500": {
            "description": "Internal server error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          }
        }
      }
    },
    "/api/list": {
      "post": {
        "summary": "List models in the library",
        "description": "List all models that are available locally",
        "operationId": "listModels",
        "responses": {
          "200": {
            "description": "Successful response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ListResponse"
                }
              }
            }
          },
          "500": {
            "description": "Internal server error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          }
        }
      }
    },
    "/api/copy": {
      "post": {
        "summary": "Copy a model",
        "description": "Create a copy of a model",
        "operationId": "copyModel",
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/CopyRequest"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/CopyResponse"
                }
              }
            }
          },
          "400": {
            "description": "Bad request",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          },
          "404": {
            "description": "Model not found",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          },
          "500": {
            "description": "Internal server error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          }
        }
      }
    },
    "/api/delete": {
      "delete": {
        "summary": "Delete a model",
        "description": "Remove a model from the library",
        "operationId": "deleteModel",
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/DeleteRequest"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/DeleteResponse"
                }
              }
            }
          },
          "400": {
            "description": "Bad request",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          },
          "404": {
            "description": "Model not found",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          },
          "500": {
            "description": "Internal server error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          }
        }
      }
    },
    "/api/show": {
      "post": {
        "summary": "Show model information",
        "description": "Show details about a model",
        "operationId": "showModel",
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/ShowRequest"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ShowResponse"
                }
              }
            }
          },
          "400": {
            "description": "Bad request",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          },
          "404": {
            "description": "Model not found",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          },
          "500": {
            "description": "Internal server error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          }
        }
      }
    },
    "/api/heartbeat": {
      "get": {
        "summary": "Check if server is running",
        "description": "Returns a heartbeat response if the server is running",
        "operationId": "heartbeat",
        "responses": {
          "200": {
            "description": "Successful response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/HeartbeatResponse"
                }
              }
            }
          },
          "500": {
            "description": "Internal server error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ErrorResponse"
                }
              }
            }
          }
        }
      }
    }
  },
  "components": {
    "schemas": {
      "GenerateRequest": {
        "type": "object",
        "required": [
          "model",
          "prompt"
        ],
        "properties": {
          "model": {
            "type": "string",
            "description": "The name of the model to use for generation",
            "example": "llama2"
          },
          "prompt": {
            "type": "string",
            "description": "The prompt to generate a response for",
            "example": "Why is the sky blue?"
          },
          "system": {
            "type": "string",
            "description": "System prompt to (overrides what is defined in the Modelfile)",
            "example": "You are a helpful assistant"
          },
          "template": {
            "type": "string",
            "description": "Prompt template to use (overrides what is defined in the Modelfile)"
          },
          "context": {
            "type": "array",
            "items": {
              "type": "integer"
            },
            "description": "The context parameter returned from a previous request to /api/generate, used to keep a short conversational memory"
          },
          "raw": {
            "type": "boolean",
            "description": "Whether to return the raw response from the model",
            "default": false
          },
          "format": {
            "type": "string",
            "description": "The format to return a response in",
            "enum": [
              "json"
            ]
          },
          "options": {
            "$ref": "#/components/schemas/ModelOptions"
          },
          "images": {
            "type": "array",
            "items": {
              "type": "string",
              "format": "binary"
            },
            "description": "List of base64-encoded images to include in the prompt (for multimodal models)"
          }
        }
      },
      "GenerateResponse": {
        "type": "object",
        "properties": {
          "model": {
            "type": "string",
            "description": "The model name",
            "example": "llama2"
          },
          "created_at": {
            "type": "string",
            "format": "date-time",
            "description": "The time the response was generated",
            "example": "2023-11-04T14:54:17.449Z"
          },
          "response": {
            "type": "string",
            "description": "The generated response",
            "example": "The sky appears blue because of a phenomenon called Rayleigh scattering."
          },
          "done": {
            "type": "boolean",
            "description": "Whether the response is complete",
            "example": true
          },
          "context": {
            "type": "array",
            "items": {
              "type": "integer"
            },
            "description": "The context parameter to pass to the next request to keep a conversational memory"
          },
          "total_duration": {
            "type": "integer",
            "format": "int64",
            "description": "The total time taken to generate the response in nanoseconds",
            "example": 5167869791
          },
          "load_duration": {
            "type": "integer",
            "format": "int64",
            "description": "The time taken to load the model in nanoseconds",
            "example": 0
          },
          "prompt_eval_count": {
            "type": "integer",
            "description": "Number of tokens in the prompt",
            "example": 8
          },
          "prompt_eval_duration": {
            "type": "integer",
            "format": "int64",
            "description": "Time spent evaluating the prompt in nanoseconds",
            "example": 326125875
          },
          "eval_count": {
            "type": "integer",
            "description": "Number of tokens in the response",
            "example": 93
          },
          "eval_duration": {
            "type": "integer",
            "format": "int64",
            "description": "Time spent generating the response in nanoseconds",
            "example": 4840869791
          }
        }
      },
      "ChatRequest": {
        "type": "object",
        "required": [
          "model",
          "messages"
        ],
        "properties": {
          "model": {
            "type": "string",
            "description": "The name of the model to use for chat",
            "example": "llama2"
          },
          "messages": {
            "type": "array",
            "items": {
              "$ref": "#/components/schemas/ChatMessage"
            },
            "description": "The list of messages in the conversation"
          },
          "stream": {
            "type": "boolean",
            "description": "Whether to stream the response",
            "default": false
          },
          "format": {
            "type": "string",
            "description": "The format to return a response in",
            "enum": [
              "json"
            ]
          },
          "options": {
            "$ref": "#/components/schemas/ModelOptions"
          },
          "template": {
            "type": "string",
            "description": "Prompt template to use (overrides what is defined in the Modelfile)"
          },
          "system": {
            "type": "string",
            "description": "System prompt to (overrides what is defined in the Modelfile)",
            "example": "You are a helpful assistant"
          },
          "keep_alive": {
            "type": "string",
            "description": "Controls how long the model will stay loaded into memory after the request completes",
            "example": "5m"
          }
        }
      },
      "ChatMessage": {
        "type": "object",
        "required": [
          "role",
          "content"
        ],
        "properties": {
          "role": {
            "type": "string",
            "description": "The role of the message sender",
            "enum": [
              "system",
              "user",
              "assistant"
            ],
            "example": "user"
          },
          "content": {
            "type": "string",
            "description": "The content of the message",
            "example": "Hello, how are you?"
          },
          "images": {
            "type": "array",
            "items": {
              "type": "string",
              "format": "binary"
            },
            "description": "List of base64-encoded images to include in the message (for multimodal models)"
          }
        }
      },
      "ChatResponse": {
        "type": "object",
        "properties": {
          "model": {
            "type": "string",
            "description": "The model name",
            "example": "llama2"
          },
          "created_at": {
            "type": "string",
            "format": "date-time",
            "description": "The time the response was generated",
            "example": "2023-11-04T14:54:17.449Z"
          },
          "message": {
            "$ref": "#/components/schemas/ChatMessage"
          },
          "done": {
            "type": "boolean",
            "description": "Whether the response is complete",
            "example": true
          },
          "total_duration": {
            "type": "integer",
            "format": "int64",
            "description": "The total time taken to generate the response in nanoseconds",
            "example": 5167869791
          },
          "load_duration": {
            "type": "integer",
            "format": "int64",
            "description": "The time taken to load the model in nanoseconds",
            "example": 0
          },
          "prompt_eval_count": {
            "type": "integer",
            "description": "Number of tokens in the prompt",
            "example": 8
          },
          "prompt_eval_duration": {
            "type": "integer",
            "format": "int64",
            "description": "Time spent evaluating the prompt in nanoseconds",
            "example": 326125875
          },
          "eval_count": {
            "type": "integer",
            "description": "Number of tokens in the response",
            "example": 93
          },
          "eval_duration": {
            "type": "integer",
            "format": "int64",
            "description": "Time spent generating the response in nanoseconds",
            "example": 4840869791
          }
        }
      },
      "EmbeddingsRequest": {
        "type": "object",
        "required": [
          "model",
          "prompt"
        ],
        "properties": {
          "model": {
            "type": "string",
            "description": "The name of the model to use for embeddings",
            "example": "llama2"
          },
          "prompt": {
            "type": "string",
            "description": "The prompt to generate embeddings for",
            "example": "Why is the sky blue?"
          },
          "options": {
            "$ref": "#/components/schemas/ModelOptions"
          },
          "keep_alive": {
            "type": "string",
            "description": "Controls how long the model will stay loaded into memory after the request completes",
            "example": "5m"
          }
        }
      },
      "EmbeddingsResponse": {
        "type": "object",
        "properties": {
          "embedding": {
            "type": "array",
            "items": {
              "type": "number",
              "format": "float"
            },
            "description": "The embedding vector"
          }
        }
      },
      "CreateRequest": {
        "type": "object",
        "required": [
          "name",
          "modelfile"
        ],
        "properties": {
          "name": {
            "type": "string",
            "description": "The name of the model to create",
            "example": "my-model"
          },
          "modelfile": {
            "type": "string",
            "description": "The contents of the Modelfile",
            "example": "FROM llama2\nSYSTEM You are a helpful assistant"
          },
          "stream": {
            "type": "boolean",
            "description": "Whether to stream the response",
            "default": false
          },
          "path": {
            "type": "string",
            "description": "Path to the model file on the server",
            "example": "/path/to/model"
          }
        }
      },
      "CreateResponse": {
        "type": "object",
        "properties": {
          "status": {
            "type": "string",
            "description": "Status message",
            "example": "success"
          },
          "error": {
            "type": "string",
            "description": "Error message if any",
            "example": ""
          }
        }
      },
      "PullRequest": {
        "type": "object",
        "required": [
          "name"
        ],
        "properties": {
          "name": {
            "type": "string",
            "description": "The name of the model to pull",
            "example": "llama2"
          },
          "stream": {
            "type": "boolean",
            "description": "Whether to stream the response",
            "default": false
          },
          "insecure": {
            "type": "boolean",
            "description": "Allow insecure connections to the library",
            "default": false
          }
        }
      },
      "PullResponse": {
        "type": "object",
        "properties": {
          "status": {
            "type": "string",
            "description": "Status message",
            "example": "success"
          },
          "error": {
            "type": "string",
            "description": "Error message if any",
            "example": ""
          },
          "digest": {
            "type": "string",
            "description": "The digest of the model",
            "example": "sha256:29fee8e3799"
          }
        }
      },
      "PushRequest": {
        "type": "object",
        "required": [
          "name"
        ],
        "properties": {
          "name": {
            "type": "string",
            "description": "The name of the model to push",
            "example": "llama2"
          },
          "stream": {
            "type": "boolean",
            "description": "Whether to stream the response",
            "default": false
          },
          "insecure": {
            "type": "boolean",
            "description": "Allow insecure connections to the registry",
            "default": false
          }
        }
      },
      "PushResponse": {
        "type": "object",
        "properties": {
          "status": {
            "type": "string",
            "description": "Status message",
            "example": "success"
          },
          "error": {
            "type": "string",
            "description": "Error message if any",
            "example": ""
          }
        }
      },
      "ListResponse": {
        "type": "object",
        "properties": {
          "models": {
            "type": "array",
            "items": {
              "$ref": "#/components/schemas/ModelInfo"
            },
            "description": "List of available models"
          }
        }
      },
      "ModelInfo": {
        "type": "object",
        "properties": {
          "name": {
            "type": "string",
            "description": "The name of the model",
            "example": "llama2"
          },
          "modified_at": {
            "type": "string",
            "format": "date-time",
            "description": "The time the model was last modified",
            "example": "2023-11-04T14:54:17.449Z"
          },
          "size": {
            "type": "integer",
            "format": "int64",
            "description": "The size of the model in bytes",
            "example": 3791309
          }
        }
      },
      "CopyRequest": {
        "type": "object",
        "required": [
          "source",
          "destination"
        ],
        "properties": {
          "source": {
            "type": "string",
            "description": "The name of the model to copy from",
            "example": "llama2"
          },
          "destination": {
            "type": "string",
            "description": "The name of the model to copy to",
            "example": "llama2-copy"
          }
        }
      },
      "CopyResponse": {
        "type": "object",
        "properties": {
          "status": {
            "type": "string",
            "description": "Status message",
            "example": "success"
          }
        }
      },
      "DeleteRequest": {
        "type": "object",
        "required": [
          "name"
        ],
        "properties": {
          "name": {
            "type": "string",
            "description": "The name of the model to delete",
            "example": "llama2"
          }
        }
      },
      "DeleteResponse": {
        "type": "object",
        "properties": {
          "status": {
            "type": "string",
            "description": "Status message",
            "example": "success"
          }
        }
      },
      "ShowRequest": {
        "type": "object",
        "required": [
          "name"
        ],
        "properties": {
          "name": {
            "type": "string",
            "description": "The name of the model to show",
            "example": "llama2"
          }
        }
      },
      "ShowResponse": {
        "type": "object",
        "properties": {
          "modelfile": {
            "type": "string",
            "description": "The contents of the Modelfile",
            "example": "FROM llama2\nSYSTEM You are a helpful assistant"
          },
          "parameters": {
            "type": "string",
            "description": "The model parameters",
            "example": "temperature 0.8"
          },
          "template": {
            "type": "string",
            "description": "The prompt template",
            "example": "[INST] {{ .Prompt }} [/INST]"
          },
          "system": {
            "type": "string",
            "description": "The system prompt",
            "example": "You are a helpful assistant"
          },
          "license": {
            "type": "string",
            "description": "The license of the model",
            "example": "Apache 2.0"
          }
        }
      },
      "HeartbeatResponse": {
        "type": "object",
        "properties": {
          "heartbeat": {
            "type": "boolean",
            "description": "Whether the server is running",
            "example": true
          }
        }
      },
      "ModelOptions": {
        "type": "object",
        "properties": {
          "temperature": {
            "type": "number",
            "format": "float",
            "description": "The temperature of the model",
            "example": 0.8
          },
          "num_ctx": {
            "type": "integer",
            "description": "Sets the size of the context window used to generate the next token",
            "example": 2048
          },
          "num_predict": {
            "type": "integer",
            "description": "Maximum number of tokens to predict",
            "example": 128
          },
          "top_k": {
            "type": "integer",
            "description": "Reduces the probability of generating nonsense",
            "example": 40
          },
          "top_p": {
            "type": "number",
            "format": "float",
            "description": "Works together with top-k",
            "example": 0.9
          },
          "tfs_z": {
            "type": "number",
            "format": "float",
            "description": "Tail free sampling is used to reduce the impact of less probable tokens",
            "example": 1
          },
          "typical_p": {
            "type": "number",
            "format": "float",
            "description": "Locally typical sampling focuses on coherent and consistent generation",
            "example": 1
          },
          "repeat_penalty": {
            "type": "number",
            "format": "float",
            "description": "Sets how strongly to penalize repetitions",
            "example": 1.1
          },
          "repeat_last_n": {
            "type": "integer",
            "description": "How far back to look for repetitions",
            "example": 64
          },
          "frequency_penalty": {
            "type": "number",
            "format": "float",
            "description": "Positive values penalize tokens that occur in the text so far",
            "example": 0
          },
          "presence_penalty": {
            "type": "number",
            "format": "float",
            "description": "Positive values penalize tokens that have already appeared in the text",
            "example": 0
          },
          "mirostat": {
            "type": "integer",
            "description": "Enable Mirostat sampling for controlling perplexity",
            "enum": [
              0,
              1,
              2
            ],
            "example": 0
          },
          "mirostat_tau": {
            "type": "number",
            "format": "float",
            "description": "Controls the balance between coherence and diversity",
            "example": 5
          },
          "mirostat_eta": {
            "type": "number",
            "format": "float",
            "description": "Learning rate for Mirostat",
            "example": 0.1
          },
          "seed": {
            "type": "integer",
            "description": "Sets the random number seed to use for generation",
            "example": 42
          },
          "stop": {
            "type": "array",
            "items": {
              "type": "string"
            },
            "description": "Sets the stop sequences to use",
            "example": [
              "###",
              "DONE"
            ]
          },
          "num_gpu": {
            "type": "integer",
            "description": "The number of layers to put on the GPU",
            "example": 50
          },
          "num_thread": {
            "type": "integer",
            "description": "Sets the number of threads to use during computation",
            "example": 8
          }
        }
      },
      "ErrorResponse": {
        "type": "object",
        "properties": {
          "error": {
            "type": "string",
            "description": "Error message",
            "example": "model not found"
          }
        }
      }
    }
  }
}